cd ~/hpfa/data_inbox
cat > cidriftcheck.py <<'PY'
#!/usr/bin/env python3
"""
cidriftcheck.py (Termux/CI friendly)

Canon (YAML/JSON) ile kod tarafı enum/state/action listelerini karşılaştırır,
drift raporu üretir. Fail-closed.

Exit codes:
  0 -> No drift (doc-only=0 and code-only=0)
  1 -> Drift detected (doc-only>0 or code-only>0)
  2 -> Input/parse error
"""

import argparse
import json
import os
import re
import sys
from typing import Any, Dict, List, Tuple

# -----------------------------
# Minimal YAML loader
# Supports a subset:
# - list of dicts using "- key: val" (your action registry YAML fits)
# - simple "key: [a,b]" or multi-line lists under key:
# -----------------------------
def _strip_comments(line: str) -> str:
    # keep quoted # (very minimal)
    if '"' in line or "'" in line:
        return line
    return line.split("#", 1)[0]

def load_yaml_minimal(path: str) -> Any:
    if not os.path.exists(path):
        raise FileNotFoundError(path)

    text = []
    with open(path, "r", encoding="utf-8") as f:
        for raw in f:
            raw = _strip_comments(raw.rstrip("\n"))
            if raw.strip():
                text.append(raw)

    # Case 1: list-of-maps style starting with "-"
    if any(re.match(r"^\s*-\s+\w+\s*:", ln) for ln in text):
        items: List[Dict[str, Any]] = []
        current: Dict[str, Any] | None = None
        for ln in text:
            m = re.match(r"^\s*-\s+(\w+)\s*:\s*(.*)\s*$", ln)
            if m:
                if current is not None:
                    items.append(current)
                current = {m.group(1): _parse_scalar(m.group(2))}
                continue

            # indented k: v under current
            m2 = re.match(r"^\s+(\w+)\s*:\s*(.*)\s*$", ln)
            if m2 and current is not None:
                k = m2.group(1)
                v = m2.group(2).strip()
                current[k] = _parse_scalar(v)
                continue

            # indented list under a key (very limited): key: then next lines "  - item"
            m3 = re.match(r"^\s+(\w+)\s*:\s*$", ln)
            if m3 and current is not None:
                k = m3.group(1)
                current[k] = []
                _current_list_key = k
                continue

            m4 = re.match(r"^\s+-\s*(.+?)\s*$", ln)
            if m4 and current is not None:
                # attach to last list key if exists
                # find last list key
                list_keys = [kk for kk, vv in current.items() if isinstance(vv, list)]
                if list_keys:
                    current[list_keys[-1]].append(_parse_scalar(m4.group(1)))
                continue

        if current is not None:
            items.append(current)
        return items

    # Case 2: key: [a,b] or key:\n  - a
    data: Dict[str, Any] = {}
    cur_key: str | None = None
    for ln in text:
        m = re.match(r"^\s*(\w+)\s*:\s*(.*)\s*$", ln)
        if m:
            cur_key = m.group(1)
            rest = m.group(2).strip()
            data[cur_key] = _parse_scalar(rest) if rest else []
            continue
        m2 = re.match(r"^\s*-\s*(.+?)\s*$", ln)
        if m2 and cur_key is not None and isinstance(data.get(cur_key), list):
            data[cur_key].append(_parse_scalar(m2.group(1)))
            continue
    return data

def _parse_scalar(v: str) -> Any:
    v = v.strip()
    if v == "":
        return ""
    # [a, b, c]
    if v.startswith("[") and v.endswith("]"):
        inner = v[1:-1].strip()
        if not inner:
            return []
        parts = [p.strip() for p in inner.split(",")]
        return [_unquote(p) for p in parts if p]
    return _unquote(v)

def _unquote(s: str) -> str:
    s = s.strip()
    if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
        return s[1:-1]
    return s

# -----------------------------
# Extractors
# -----------------------------
def extract_canon_from_action_registry(obj: Any) -> Dict[str, List[str]]:
    """
    Accepts your YAML list-of-maps:
      - canonical_action: GK_CATCH
        aliases: [...]
        possession_effect: START
        allowed_states: [...]
        fail_closed_default: UNVALIDATED
    """
    out: Dict[str, List[str]] = {
        "canonical_actions": [],
        "aliases": [],
        "possession_effects": [],
        "allowed_states": [],
        "fail_closed_defaults": [],
    }
    if not isinstance(obj, list):
        return out

    for item in obj:
        if not isinstance(item, dict):
            continue
        ca = item.get("canonical_action")
        if isinstance(ca, str):
            out["canonical_actions"].append(ca)

        al = item.get("aliases", [])
        if isinstance(al, list):
            out["aliases"].extend([a for a in al if isinstance(a, str)])

        pe = item.get("possession_effect")
        if isinstance(pe, str):
            out["possession_effects"].append(pe)

        st = item.get("allowed_states", [])
        if isinstance(st, list):
            out["allowed_states"].extend([s for s in st if isinstance(s, str)])

        fd = item.get("fail_closed_default")
        if isinstance(fd, str):
            out["fail_closed_defaults"].append(fd)

    # dedupe
    for k in out:
        out[k] = sorted(set(out[k]))
    return out

# -----------------------------
# Drift logic
# -----------------------------
def similar(a: str, b: str) -> bool:
    na = re.sub(r"[\s\-]+", "_", a.lower())
    nb = re.sub(r"[\s\-]+", "_", b.lower())
    ta = set(na.split("_"))
    tb = set(nb.split("_"))
    if not ta or not tb:
        return False
    overlap = len(ta & tb) / max(len(ta), len(tb))
    return overlap >= 0.6

def compare_lists(doc_list: List[str], code_list: List[str]) -> Tuple[List[str], List[str], List[Tuple[str, str]]]:
    docset = set(doc_list)
    codeset = set(code_list)

    doc_only = sorted(docset - codeset)
    code_only = sorted(codeset - docset)

    mismatches: List[Tuple[str, str]] = []
    # try to pair similar terms doc-only <-> code-only
    remaining_doc = doc_only[:]
    remaining_code = code_only[:]
    for d in remaining_doc:
        for c in remaining_code:
            if similar(d, c):
                mismatches.append((d, c))
                if d in doc_only:
                    doc_only.remove(d)
                if c in code_only:
                    code_only.remove(c)
                remaining_code.remove(c)
                break

    return doc_only, code_only, mismatches

def build_report(canon: Dict[str, List[str]], code: Dict[str, List[str]]) -> Dict[str, Any]:
    report: Dict[str, Any] = {"summary": {}, "details": {}}

    all_keys = sorted(set(canon.keys()) | set(code.keys()))
    total_doc_only = 0
    total_code_only = 0
    total_warn = 0

    for key in all_keys:
        doc_list = canon.get(key, [])
        code_list = code.get(key, [])

        doc_only, code_only, mismatches = compare_lists(doc_list, code_list)

        report["details"][key] = {
            "doc_only": doc_only,
            "code_only": code_only,
            "mismatch": [{"doc": d, "code": c} for d, c in mismatches],
        }

        total_doc_only += len(doc_only)
        total_code_only += len(code_only)
        total_warn += len(mismatches)

    report["summary"] = {
        "doc_only_count": total_doc_only,
        "code_only_count": total_code_only,
        "mismatch_count": total_warn,
    }
    return report

def write_json(report: Dict[str, Any], path: str) -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

def write_markdown(report: Dict[str, Any], path: str) -> None:
    with open(path, "w", encoding="utf-8") as f:
        f.write("# Drift Report\n\n")
        f.write("## Summary\n")
        f.write(f"- Doc-only: {report['summary']['doc_only_count']}\n")
        f.write(f"- Code-only: {report['summary']['code_only_count']}\n")
        f.write(f"- Mismatch (WARN): {report['summary']['mismatch_count']}\n\n")
        f.write("## Details\n\n")
        for key, block in report["details"].items():
            f.write(f"### {key}\n")
            f.write(f"- Doc-only: {block['doc_only']}\n")
            f.write(f"- Code-only: {block['code_only']}\n")
            f.write(f"- Mismatch: {block['mismatch']}\n\n")

# -----------------------------
# Minimal "code enums" input
# For now expects a JSON file like:
# {"canonical_actions":[...],"allowed_states":[...],...}
# -----------------------------
def load_code_enums_json(path: str) -> Dict[str, List[str]]:
    if not os.path.exists(path):
        raise FileNotFoundError(path)
    obj = json.load(open(path, "r", encoding="utf-8"))
    out: Dict[str, List[str]] = {}
    for k, v in obj.items():
        if isinstance(v, list):
            out[k] = [str(x) for x in v]
    return out

def main() -> None:
    p = argparse.ArgumentParser()
    p.add_argument("--canon-action-registry", required=True, help="HPFA canonical action registry YAML")
    p.add_argument("--code-enums", required=True, help="Code enums JSON (exported from code)")
    p.add_argument("--out-json", default="drift_report.json")
    p.add_argument("--out-md", default="drift_report.md")
    args = p.parse_args()

    try:
        canon_obj = load_yaml_minimal(args.canon_action_registry)
        canon = extract_canon_from_action_registry(canon_obj)
        code = load_code_enums_json(args.code_enums)
        report = build_report(canon, code)
        write_json(report, args.out_json)
        write_markdown(report, args.out_md)
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        sys.exit(2)

    if report["summary"]["doc_only_count"] > 0 or report["summary"]["code_only_count"] > 0:
        sys.exit(1)
    sys.exit(0)

if __name__ == "__main__":
    main()
PY
chmod +x cidriftcheck.py
